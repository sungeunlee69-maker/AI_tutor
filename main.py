import streamlit as st
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI íŠœí„° ë‰´í„´", page_icon="ğŸ")
st.header("ğŸ ê³¼í•™ ì „ë¬¸ AI íŠœí„° 'ë‰´í„´'")

# 2. API ì„¤ì • (ì¤‘ìš”: Client ëŒ€ì‹  configureë¥¼ ì”ë‹ˆë‹¤)
API_KEY = "AIzaSyDoqIexHHHjWNL9QR1yci3SMavjHUXax58" 
genai.configure(api_key=API_KEY)

# 3. ë‰´í„´ì˜ êµìœ¡ í˜ë¥´ì†Œë‚˜
instruction = """ë„ˆëŠ” ì´ˆì¤‘ê³  ê³¼í•™ ì „ë¬¸ êµì‚¬ AI íŠœí„° 'ë‰´í„´'ì´ì•¼.
- ë”°ëœ»í•˜ê²Œ ê²©ë ¤í•˜ë©° ëŒ€í™”ë¥¼ ì‹œì‘í•´ì¤˜.
- ë¹„ìœ ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê²Œ ìœ ë„í•´ì¤˜.
- ë§ˆì§€ë§‰ì—” í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸ì„ ë˜ì ¸ì¤˜."""

# 4. ëª¨ë¸ ì„¤ì • (êµ¬í˜•/ì‹ í˜• ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë‘ì—ì„œ ê°€ì¥ ì•ˆì •ì ì¸ í˜¸ì¶œ ë°©ì‹)
model = genai.GenerativeModel('gemini-1.5-flash')

# 5. ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 6. ì‚¬ìš©ì ì…ë ¥ ë° ë‹µë³€ ìƒì„±
if prompt := st.chat_input("ì˜¤ëŠ˜ ë°°ìš´ ê³¼í•™ ì¤‘ ê¶ê¸ˆí•œ ê²Œ ìˆë‚˜ìš”?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        # Client ë°©ì‹ì´ ì•„ë‹Œ GenerativeModelì˜ ì§í†µ ë°©ì‹ì„ ì”ë‹ˆë‹¤.
        full_prompt = f"ì§€ì¹¨: {instruction}\n\ní•™ìƒ ì§ˆë¬¸: {prompt}"
        response = model.generate_content(full_prompt)
        
        with st.chat_message("assistant"):
            st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})
        
    except Exception as e:
        st.error(f"ë‰´í„´ ì„ ìƒë‹˜ê³¼ ì—°ê²° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
